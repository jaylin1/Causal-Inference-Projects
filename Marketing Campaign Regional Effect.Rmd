---
title: "Experiment Design: Marketing Campaign Regional Effect"
author: "Johnathan Lin"
date: "2025-06-20"
output: html_document
---

```{r packages setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(lmtest)
library(sandwich)
library(ggplot2)
library(pwr)

```

```{r}
set.seed(42)

```

```{r}
weeks <- 24
n_regions <- 2
regions <- c("NYC", "Boston")
treatment_week <- 19
```

```{r}
df <- expand.grid(week = 1:weeks, region = regions)
df <- df %>% 
  mutate(treated = ifelse(region == "NYC", 1, 0),
         post = ifelse(week >= treatment_week, 1,0),
         
         did = treated * post,
         base_sales = 100 +rnorm(n(), 5) # base sales : 100
         )
```

```{r}
df <- df %>% 
  mutate(treatment_effect = ifelse(did == 1, 20, 0),
         sales = base_sales + treatment_effect
         )
head(df)
```

```{r , message=FALSE, warning=FALSE}
ggplot(df, aes (x= week, y = sales, color =region, group = region)) +
  geom_line(size = 1.2) + 
  geom_vline(xintercept = treatment_week, linetype = "dashed", color = 'black') +
  labs( title = "Weekly Sales by Region", subtitle = "Dashed Line: Treatment Starts in NYC", y = "Sales", x = "Week") +
  scale_x_continuous(breaks = seq(min(df$week), max(df$week), by = 1)) 
```

```{r}
baseline_nyc <- df %>% 
  filter(region == "NYC", week < treatment_week) %>% 
  summarize(mean_sales = mean(sales)) %>% 
  pull(mean_sales)

baseline_nyc
```

```{r}
# assuming mde of 2%
effect_units <- 0.02 * baseline_nyc
effect_units
```

```{r}
sd_sales = df %>% 
  filter(week < treatment_week) %>% 
  summarize(sd = sd(sales)) %>% 
  pull(sd)
sd_sales
```

```{r}
d <- effect_units / sd_sales
d
```

```{r}
# calculate power of treatment in 6 weeks
pwr.t.test(d = 2.750816 , n = 6 , sig.level = 0.05,  type = "two.sample")
```

If there was truly a 2% lift in NYC sales due to the campaign, then given our sample size and variability, we would detect that effect with 99% probability.

There is only 1.04% chance that I'd miss a true effect of that size (Type II error).

```{r}

d = pwr.t.test( n = 6 , sig.level = 0.05, power =0.8,  type = "two.sample")$d
pwr.t.test( n = 6 , sig.level = 0.05, power =0.8,  type = "two.sample")
```

```{r}
sd_pre <- df %>% 
  filter(week < treatment_week) %>% 
  summarize(sd_sales = sd(sales)) %>% 
  pull(sd_sales)
  
baseline_nyc <- df %>%
  filter(region == "NYC", week < treatment_week) %>%
  summarize(mean_sales = mean(sales)) %>%
  pull(mean_sales)

```

```{r}
mde_units <- d * sd_pre
mde_units
```

```{r}
mde_pct <- (mde_units/baseline_nyc) *100
mde_pct
```

Given 6 weeks to test the marketing campaign, with the desired significance level and power, the minimum detectable change is 1.96 units or a lift percent of 1.87%

If we wanted to detect at least a 2% lift, our current testing set up would allow for that.

# How MDE changes given sample size n?

We want to examine if we run the marketing campaign for longer, how would this affect our ability to actually measure the impact of it if there were any.

```{r}

weeks_range <- 3:12

compute_mde <- function(n_weeks, sd, baseline){
  d_mde <- pwr.t.test( n = n_weeks , sig.level = 0.05, power =0.8,  type = "two.sample", alternative = "two.sided")$d
  mde_units <- d_mde * sd
  mde_pct <- (mde_units/baseline) * 100
  return(data.frame(weeks = n_weeks,
                    d = d_mde,
                    mde_units,
                    mde_pct
                    ))
}
```


```{r}
baseline_nyc <- df %>%
  filter(region == "NYC", week < treatment_week) %>%
  summarize(mean_sales = mean(sales)) %>%
  pull(mean_sales)
```


```{r}
mde_table <- lapply(weeks_range, compute_mde, sd = sd_pre, baseline = baseline_nyc) %>% 
  bind_rows()
```

```{r}
knitr::kable(round(mde_table, 2), caption = "Minimum Detectable Effect by Week")
```

```{r}
ggplot(mde_table, aes( x= weeks, y= mde_pct)) + 
  geom_line(size = 1.2, color = "steelblue") + 
  geom_point( size = 2) + 
  geom_hline(yintercept =  2, linetype = "dashed", color = "red" ) + 
  labs(title = "Minimum Detectable % Sales vs Number of Post-treatment weeks",
       x = "Post treatment weeks",
       y = "Minimum Detectable Lift %") + 
  scale_x_continuous(breaks = weeks_range)  

```

The more weeks we allow the marketing campaign to run for the smaller the minimum detectable effect size becomes.

# Significance Levels

At the current significance level of 0.05 and power of 0.8, we can detect a minimum lift of 0.91% in sales with 80% power after 12 weeks of treatment.

Suppose the implications of making the wrong decision are severe, we might want to lower the significance level to account for that.

```{r}
pwr.t.test(d = 1.924106 , sig.level = 0.05
           , power = 0.8, type = "two.sample", alternative = "two.sided")$n
```

```{r}
d <- 2.099254 / 1.091028
alpha_levels <- seq(.05 , .01, by = -.01)

weeks_required <- data.frame(alpha = alpha_levels, n_required = sapply(alpha_levels, function(a) {
  ceiling(pwr.t.test(d = d, sig.level = a, power = 0.8, type = "two.sample")$n)
}))
weeks_required
```

```{r}
ggplot(weeks_required, aes(x = alpha, y = n_required)) +
  geom_line(size = 1.2, color = "Red") +
  geom_point(size = 2) + 
  scale_x_reverse(breaks = alpha_levels) +
  labs(title ="Weeks required for 2% lift with 80% power",
       x = "Significance Level (alpha)",
       y = "Required Weeks per Group") +
  theme_minimal()
```

If the cost of the marketing campaign is high, we might want to run the campaign for longer to account for a more stringent alpha level to avoid false positives as the cost of a false positive is high.
